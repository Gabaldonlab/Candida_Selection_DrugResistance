#!/usr/bin/env python

# This is the main script

########## ENV ##########

# get environment
import sys, os, re, argparse
import pandas as pd
from argparse import RawTextHelpFormatter
from ete3 import Tree

# get the cwd were all the scripts are 
CWD = "/".join(__file__.split("/")[0:-1]); sys.path.insert(0, CWD)

# get functions
import tree_functions as fun

# define the EnvDir where the environment is defined
EnvDir = "/".join(sys.executable.split("/")[0:-2])
CondaDir =  "/".join(sys.executable.split("/")[0:-4])
EnvName = EnvDir.split("/")[-1]

#########################

###### ARGS #####

description = """
This script generates a tree for several samples given the variants and the sorted bam files. It requires files generated by perSVade (or equivalent). There are two different modes of running:

HAPLOID MODE (--mode haploid):

    In the haploid mode it generates a pseudo-genome sequence for each sample based on the reference genome but substituting the reference sequences according to haploid SNPs. To avoid the biases introduced by CNVs and INDELs, these pseudo-genomes only include positions matching the following criteria in all samples: 1) coverage>12x (default), 2) absence of INDELs and 3) absence of heterozygous diploid SNPs. In addition, they only include variable positions. It uses Biopython and bedmap to obtain the aligned pseudo-genomes. It then obtains the unrooted tree with iqtree from these aligned pseudo-genomes using ‘-m TEST+ASC’, to use default automatic model selection and ascertainment bias correction (which is necessary to calculate meaningful branch lengths). It then uses midpoint rooting to get the final tree, which has support values from 1000 bootstraps.

    To run in haploid mode you'll need to provide a table with the columns "sampleID", "sorted_bam", "vcf_haploid" and/or "vcf_diploid". The columns "sampleID", "sorted_bam" and "vcf_haploid" are mandatory, and the "vcf_diploid" is optional. If you skip the column "vcf_diploid", but this will likely generate a less accurate tree because heterozygous mutations won't be filtered out (as heterozygous variants are only identified in the diploid vcf). Furthermore, you need to custmize the minimum coverage with --min_coverage_pos. 

DIPLOID HOMOZYGOUS MODE (--mode diploid_homozygous)

    In the diploid homozygous mode it runs a pipeline that is equivalent to the haploid mode, but considering homozygous SNPs instead of haploid SNPs. This is useful for diploid species that have low heterozygosity. Thus, the pseudo-genomes will only include positions matching the following criteria in all samples: 1) coverage>12x (default), 2) absence of INDELs and 3) absence of heterozygous diploid SNPs.

    To run in diploid homozygous mode you'll need to provide a table with the columns "sampleID", "sorted_bam" and "vcf_diploid". Furthermore, you need to custmize the minimum coverage with --min_coverage_pos. 

DIPLOID MODE (--mode diploid):

    In the diploid mode it runs a tree-generation method, inspired by O'Brien 2021, to take into account both homozygous and heterozygous SNPs. It generates 100 pseudo-genome sequences for each sample based on the reference genome, but substituting the reference sequences according to SNPs (only those that have defined heterozygous or homozygous genotype calls). These pseudo-genomes only included positions matching the following criteria in all strains: 1) coverage>12x (default) and 2) absence of INDELs. Each of these 100 pseudo-genomes included all homozygous SNPs and a random selection of heterozygous SNPs (each heterozygous SNP with a probability of 0.5 to be included). It then obtaines one unrooted tree for each of these 100 aligned pseudo-genomes (with only variable positions) with iqtree using ‘-m GTR+F+ASC+G4’ (equivalent to the ​​“GTRGAMMA” model used in O'Brien 2021), required to have a consistent model and ascertainment bias correction. It roots all 100 trees with midpoint rooting (not relying on outgroups), and generates a final consensus tree with branch lengths using iqtree (-con argument) followed by the consensus.edges function from phytools. Note that the branch support for this consensus tree is derived from the number of re-sampled trees including a given branch. This mode is useful for diploid species that have high heterozygosity.

    To run in diploid mode you'll need to provide a table with the columns "sampleID", "sorted_bam", "vcf_diploid". This pipeline for diploids requires generating 100 trees by default, which will take a lot of time. You can optimize this in two ways. On the one hand, you may run this script with the --batch_mode argument. In batch mode this scropt i) generates a file with 100 (default) tree-generation commands (one command in each line) and ii) exits the execution. You can run these commands in a cluster (i.e. with greasy) and then re-run this script (get_tree.py) to perform the last part of the algorithm (generation of the consensus tree). On the other hand, you can reduce the number of re-samples with --n_resampled_trees <number> (default 100), which will reduce the computational burden. Furthermore, you need to custmize the minimum coverage with --min_coverage_pos. 

"""

parser = argparse.ArgumentParser(description=description, formatter_class=RawTextHelpFormatter)

# mandatory args
parser.add_argument("--paths_table", dest="paths_table", action="store", type=str, required=True, help="Path to the table with the samples to use. It should contain one row for each sample. The columns 'sampleID', 'sorted_bam' are mandatory, as these specify the samples and the aligned reads. In addition, the other allowed columns are 'vcf_haploid' and 'vcf_diploid', which are the paths to the variants. When running with '--mode haploid' you need to provide 'vcf_haploid', and you may also provide 'vcf_diploid' to filter out posiions with heterozygous SNPs. When running with '--mode diploid' you have to provide only 'vcf_diploid'")
parser.add_argument("-o", "--outdir", dest="outdir", action="store", type=str, required=True, help="Output directory, where all files will be saved")
parser.add_argument("--mode", dest="mode", action="store", type=str, required=True, help="Tree running mode ('diploid', 'diploid_homozygous' or 'haploid')")
parser.add_argument("--threads", dest="threads", action="store", type=int, required=True, help="Number of threads to use in parallel operations (i.e. coverage per position calculation and tree reconstruction).")
parser.add_argument("--min_coverage_pos", dest="min_coverage_pos", required=True, type=int, help="Minimum coverage required for a position to be required. We used commonly 12, but this will depend on your dataset.")

# optional args
parser.add_argument("--reference_genome", dest="reference_genome", action="store", type=str, default=None, help="Reference genome in fasta format. Only required for diploid mode.")
parser.add_argument("--replace", dest="replace", action="store_true", help="Re-run all the steps by deleting the output directory.")
parser.add_argument("--batch_mode", dest="batch_mode", action="store_true", help="Run diploid mode in batch mode. If you specify this command you need to run the pipeline in three phases. 1) Run 'get_tree.py' until it has generated 100 (default) tree-generation commands, saved in <outdir>/jobs_tree_generation.txt. 2) Run the commands of <outdir>/jobs_tree_generation.txt (i.e. with greasy in an HPC cluster). 3) Run againg 'get_tree.py', which will integrate the trees generated into a consensus tree.")
parser.add_argument("--n_resampled_trees", dest="n_resampled_trees", default=100, type=int, help="Number of resmpled trees. 100 is the default")


# parse
opt = parser.parse_args()

#################

##### DEBUG INPUTS ######

# rename
opt.outdir = fun.get_fullpath(opt.outdir)

# remove outdir if replace, and set replace to False
if opt.replace is True: fun.delete_folder(opt.outdir)

# make the outdir
fun.make_folder(opt.outdir)

# define tmp dir
tmpdir = "%s/tmp"%opt.outdir; fun.make_folder(tmpdir)

# exit if the final file exists
final_file = "%s/tree_generated.txt"%opt.outdir

if not fun.file_is_empty(final_file): 
    print("WARNING: %s exists, suggesting that get_tree.py was already  run in this folder. Remove this file if you want this command to work. Exiting..."%final_file)
    sys.exit(0)

# load df of paths and debug
df_paths = fun.get_tab_as_df_or_empty_df(opt.paths_table)

for f in ["sorted_bam", "sampleID"]:
    if f not in df_paths.keys(): raise ValueError("%s column should be in --paths_table"%f)

if opt.mode=="haploid": 
    if "haploid_vcf" not in df_paths.keys(): raise ValueError("haploid_vcf column should be in --paths_table")

    if "diploid_vcf" in df_paths.keys(): calling_ploidies = [1, 2]
    else:
        calling_ploidies = [1]
        print("WARNING: 'diploid_vcf' was not provided. Thus, positions with heterozygous SNPs cannot be removed. This may generate a slightly less accurate tree.")

    if opt.batch_mode is True: raise ValueError("You specified the --batch_mode, which makes no sense for haploids")

elif opt.mode in {"diploid", "diploid_homozygous"}: 
    if "diploid_vcf" not in df_paths.keys(): raise ValueError("diploid_vcf column should be in --paths_table")
    calling_ploidies = [2]

else: raise ValueError("invalid mode: %s"%opt.mode)

if opt.mode=="diploid" and opt.reference_genome is None: raise ValueError("You shoul provide a --reference_genome for mode=diploid")

if opt.n_resampled_trees<50: print("WARNING: You are running with <50 (--n_resampled_trees %i) resampled trees. This may generate inaccurate branch supports."%opt.n_resampled_trees)

for f in ["sorted_bam", "haploid_vcf", "diploid_vcf"]: 
    if f in df_paths.keys(): 
        df_paths[f] = df_paths[f].apply(fun.get_fullpath)
        for file in df_paths[f]:
            if fun.file_is_empty(file): raise ValueError("File '%s', provided in --paths_table, is unexistent / empty"%file)

if len(set(df_paths.sampleID))!=len(df_paths): raise ValueError("sampleID should be unique")

df_paths["sampleID"] = df_paths.sampleID.apply(str)

#########################

#### CODE ####

# get the dataframe with the variants (the file)
small_vars_df_file = fun.get_small_vars_df_file_from_df_paths(df_paths, calling_ploidies, tmpdir)

# define the df with the bams
df_sorted_bams = df_paths[["sampleID", "sorted_bam"]]

# define the samples
sorted_samples = sorted(set(df_sorted_bams.sampleID))

# define the final tree
final_tree = "%s/rooted_tree_mode=%s_min_cov=%i.nw"%(opt.outdir, opt.mode, opt.min_coverage_pos)

# run tree
print("Getting tree in %s mode. All output files will be stored in %s"%(opt.mode, opt.outdir))
if opt.mode in {"haploid", "diploid_homozygous"}:

    # generate a df with the SNPs that are in positions with coverage >12x in all samples, have no heterozygous SNPs and have no IN/DELs
    haploid_snps_df_uniFormPositions_file = "%s/haploid_snps_df_uniFormPositions_file.py"%tmpdir
    outdir_generateHaploidSNPs_df = "%s/generating_haploid_snps_df_uniFormPositions_file"%tmpdir
    fun.generate_haploid_snps_df_uniFormPositions_file(small_vars_df_file, df_sorted_bams, haploid_snps_df_uniFormPositions_file, opt.min_coverage_pos, outdir_generateHaploidSNPs_df, opt.mode, threads=opt.threads)
    fun.delete_folder(outdir_generateHaploidSNPs_df) # clean

    # generate a fasta file with the haploid SNPs
    haploid_snps_multifasta = "%s/haploid_positions_noINDELS_noHetSNPs_sequence.fasta"%tmpdir
    snps_df = fun.load_object(haploid_snps_df_uniFormPositions_file).set_index("sampleID", drop=False)
    if len(snps_df)==0: raise ValueError("There are 0 SNPs")
    fun.generate_multifasta_from_snps_df(snps_df, haploid_snps_multifasta, sorted_samples, threads=opt.threads, generate_one_aln_each_chrom=True, pickRandomHetSNPs=False)

    # generate a concatenated alignment with only variable positions
    haploid_snps_multifasta_onlyVariableSites = "%s.onlyVariableSites.fasta"%haploid_snps_multifasta
    fun.get_multifasta_onlyVariableSites("%s.positions_df.py"%haploid_snps_multifasta, haploid_snps_multifasta_onlyVariableSites, sorted_samples, replace=False)

    # generate the tree
    outdir_tree = "%s/generate_tree_from_SNPs"%opt.outdir; fun.make_folder(outdir_tree)
    outfileprefix= "%s/iqtree_unroted"%outdir_tree
    std_iqtree = "%s.std"%outfileprefix

    print("Running iqtree to get tree. Log in '%s'..."%(std_iqtree))
    if fun.file_is_empty("%s.iqtree"%outfileprefix): fun.run_cmd("iqtree -s '%s' -pre %s --mem 25G -m TEST+ASC -T AUTO -B 1000 > %s 2>&1"%(haploid_snps_multifasta_onlyVariableSites, outfileprefix, std_iqtree), env=EnvName)

    # generate the rooted the tree with midpoint rooting
    tree = fun.get_correct_tree_midpointRooted("%s/iqtree_unroted.treefile"%(outdir_tree))
    tree.write(outfile=final_tree, format=2)

elif opt.mode=="diploid":

    # change the place of the reference genome
    dest_ref = "%s/reference_genome.fasta"%tmpdir
    fun.soft_link_files(opt.reference_genome, dest_ref)
    opt.reference_genome = dest_ref

    # perform general genome operations
    fun.index_genome(opt.reference_genome)
    fun.create_sequence_dict(opt.reference_genome)
    fun.get_chr_to_len(opt.reference_genome)

    # get a df with with diploid SNPs in positions that are covered and have no indels in all samples
    homo_and_hetero_snps_df_correctPositions_file = "%s/homo_and_hetero_SNPs_positions_noINDELS.py"%tmpdir        
    outdir_SNPs = "%s/generating_homo_and_hetero_snps_df_correctPositions_file"%tmpdir
    fun.generate_homo_and_hetero_snps_df_correctPositions(small_vars_df_file, df_sorted_bams, homo_and_hetero_snps_df_correctPositions_file, opt.min_coverage_pos, outdir_SNPs, threads=opt.threads)
    fun.delete_folder(outdir_SNPs)

    # define a dir with all the trees
    outdir_tree_resampling = "%s/generate_tree_from_SNPs_resamplingHetSNPs"%tmpdir; fun.make_folder(outdir_tree_resampling)
    outdir_resamplings = "%s/resamplings"%outdir_tree_resampling; fun.make_folder(outdir_resamplings)

    # make a file with all samples
    samples_file = "%s/samples.tab"%outdir_tree_resampling
    df_sorted_bams[["sampleID"]].to_csv(samples_file, sep="\t", index=False, header=True)

    # generate n_resampled_trees cmds trees for pseudoalignments with randomly chosen heterozygous SNPs
    all_cmds = []
    trees_list = []
    for I in range(1, opt.n_resampled_trees+1):

        # define files
        outdir_I = "%s/resample_%i"%(outdir_resamplings, I); fun.make_folder(outdir_I)
        final_file_I = "%s/tree_was_generated.txt"%outdir_I
        tree_file_I = "%s/iqtree_unroted.treefile"%outdir_I
        std_I = "%s/tree_generation.log"%outdir_I

        # keep cmd for tree reconstruction (if not already done)
        if fun.file_is_empty(final_file_I): all_cmds.append("%s/get_tree_from_snps_df_resamplingHeteroSNPs.py --outdir %s --ref %s --threads %i --snps_df_file %s --samples_file %s > %s 2>&1"%(CWD, outdir_I, opt.reference_genome, opt.threads, homo_and_hetero_snps_df_correctPositions_file, samples_file, std_I))

        # keep resampled tree if generated
        elif not fun.file_is_empty(tree_file_I): trees_list.append(tree_file_I) 

        # debug
        else: raise ValueError("File %s should exist"%tree_file_I)

    # run cmds
    if len(all_cmds)>0:

        # run sequentially
        if opt.batch_mode is False:
            print("Running %i tree-generation commands sequentially (slow mode)..."%(len(all_cmds)))
            for Ic, cmd in enumerate(all_cmds): 
                print("Running cmd %i/%i. The log is in '%s'"%(Ic+1, len(all_cmds), cmd.split(">")[1].split()[0]))
                fun.run_cmd(cmd, env=EnvName)

        else:
            jobs_file = "%s/jobs_tree_generation.txt"%opt.outdir
            open(jobs_file, "w").write("\n".join(all_cmds))
            print("Running in batch mode. Generating '%s', a file where each line is a command to generate a tree based on randomly sampled heterozygous SNPs (%i commands in total). You should run these commands (perhaps in parallel in an HPC cluster) and, once they finish correctly, re-run this script (get_tree.py) with the same arguments to continue the last steps of generation.\nExiting execution because some jobs need to be run...."%(jobs_file, len(all_cmds)))
            sys.exit(0)


    # generate a consensus tree (no branch lengths)
    print("generating consensus tree")
    consensus_treefile_withBL, all_trees_file = fun.generate_consensus_withBootstrap_from_resampledTrees(trees_list, outdir_tree_resampling, replace=False)

    # keep some files
    fun.rsync_file(consensus_treefile_withBL, final_tree)
    fun.rsync_file(all_trees_file, "%s/resampled_trees.txt"%opt.outdir)

    tree_logs_dir = "%s/tree_generation_logs"%opt.outdir; fun.make_folder(tree_logs_dir)
    for I in range(1, opt.n_resampled_trees+1): 
        outdir_I = "%s/resample_%i"%(outdir_resamplings, I)
        fun.rsync_file("%s/iqtree_unroted.iqtree"%outdir_I, "%s/resample%i.iqtree"%(tree_logs_dir, I))

else: raise ValueError("invalid mode: %s"%opt.mode)

##############


##### CLEAN AND REPORT ####

# clean
fun.delete_folder(tmpdir)

# log
print("You generated the tree successfully! The tree is in '%s'."%(final_tree))

# create final file
open(final_file, "w").write("Tree was generated successfully.\n")


###########################